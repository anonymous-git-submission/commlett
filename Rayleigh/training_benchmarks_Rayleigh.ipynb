{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEAfQA05D6ua"
      },
      "source": [
        "# Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAkyZrEzu97V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import platform\n",
        "from tensorflow.keras import layers, optimizers, losses, models, Input, Model\n",
        "import time # Per misurare il tempo di training\n",
        "from tensorflow.keras.callbacks import EarlyStopping # Per l'early stopping\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm # Per mostrare una barra di progresso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AujxZNQWMBuP"
      },
      "source": [
        "# Set seeds for random operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXGzTxrOME1z"
      },
      "outputs": [],
      "source": [
        "# --- 1. Impostazione del Seed Globale all'inizio del tuo script ---\n",
        "# Questo è il punto chiave per la riproducibilità di TUTTO ciò che segue.\n",
        "MASTER_RANDOM_SEED = 42\n",
        "np.random.seed(MASTER_RANDOM_SEED)\n",
        "random.seed(MASTER_RANDOM_SEED) # Imposta anche il seed per la libreria 'random' di Python se la usi\n",
        "tf.random.set_seed(MASTER_RANDOM_SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(MASTER_RANDOM_SEED) # Per operazioni basate su hash (es. ordine dei dizionari)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1' # Forza operazioni deterministiche in TensorFlow 2.x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBZ65HW9CLdc"
      },
      "source": [
        "# Print the HW Specs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBhq145cCO9I",
        "outputId": "9f10d3f9-f34c-40a8-fd4c-7624f9da5f31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Dettagli dell'Architettura Hardware della Sessione Colab ---\n",
            "\n",
            "--- Dettagli CPU ---\n",
            "Architecture:             x86_64\n",
            "  CPU op-mode(s):         32-bit, 64-bit\n",
            "  Address sizes:          46 bits physical, 48 bits virtual\n",
            "  Byte Order:             Little Endian\n",
            "CPU(s):                   2\n",
            "  On-line CPU(s) list:    0,1\n",
            "Vendor ID:                GenuineIntel\n",
            "  Model name:             Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "    CPU family:           6\n",
            "    Model:                79\n",
            "    Thread(s) per core:   2\n",
            "    Core(s) per socket:   1\n",
            "    Socket(s):            1\n",
            "    Stepping:             0\n",
            "    BogoMIPS:             4399.99\n",
            "    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge m\n",
            "                          ca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht sysc\n",
            "                          all nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xt\n",
            "                          opology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq\n",
            "                           ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt\n",
            "                           aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dno\n",
            "                          wprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase\n",
            "                           tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm r\n",
            "                          dseed adx smap xsaveopt arat md_clear arch_capabilitie\n",
            "                          s\n",
            "Virtualization features:  \n",
            "  Hypervisor vendor:      KVM\n",
            "  Virtualization type:    full\n",
            "Caches (sum of all):      \n",
            "  L1d:                    32 KiB (1 instance)\n",
            "  L1i:                    32 KiB (1 instance)\n",
            "  L2:                     256 KiB (1 instance)\n",
            "  L3:                     55 MiB (1 instance)\n",
            "NUMA:                     \n",
            "  NUMA node(s):           1\n",
            "  NUMA node0 CPU(s):      0,1\n",
            "Vulnerabilities:          \n",
            "  Gather data sampling:   Not affected\n",
            "  Itlb multihit:          Not affected\n",
            "  L1tf:                   Mitigation; PTE Inversion\n",
            "  Mds:                    Vulnerable; SMT Host state unknown\n",
            "  Meltdown:               Vulnerable\n",
            "  Mmio stale data:        Vulnerable\n",
            "  Reg file data sampling: Not affected\n",
            "  Retbleed:               Vulnerable\n",
            "  Spec rstack overflow:   Not affected\n",
            "  Spec store bypass:      Vulnerable\n",
            "  Spectre v1:             Vulnerable: __user pointer sanitization and usercopy b\n",
            "                          arriers only; no swapgs barriers\n",
            "  Spectre v2:             Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-eIB\n",
            "                          RS: Not affected; BHI: Vulnerable\n",
            "  Srbds:                  Not affected\n",
            "  Tsx async abort:        Vulnerable\n",
            "\n",
            "\n",
            "--- Dettagli RAM (Memoria) ---\n",
            "MemTotal:       13289424 kB\n",
            "\n",
            "\n",
            "--- Dettagli Spazio su Disco ---\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         113G   39G   75G  34% /\n",
            "\n",
            "\n",
            "--- Dettagli Acceleratore Hardware (GPU/TPU) ---\n",
            "Tipo Acceleratore: GPU\n",
            "  - Dispositivo GPU rilevato: /physical_device:GPU:0\n",
            "\n",
            "Dettagli GPU specifici (da `!nvidia-smi`):\n",
            "Wed Jul 30 11:44:07 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8             10W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "--- Analisi Dettagli Hardware Completata ---\n"
          ]
        }
      ],
      "source": [
        "print(\"--- Dettagli dell'Architettura Hardware della Sessione Colab ---\\n\")\n",
        "\n",
        "# --- 1. Dettagli CPU ---\n",
        "print(\"--- Dettagli CPU ---\")\n",
        "!lscpu\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 2. Dettagli RAM (Memoria) ---\n",
        "print(\"--- Dettagli RAM (Memoria) ---\")\n",
        "!cat /proc/meminfo | grep MemTotal\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 3. Dettagli Spazio su Disco ---\n",
        "print(\"--- Dettagli Spazio su Disco ---\")\n",
        "!df -h /\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 4. Dettagli Acceleratore Hardware (GPU/TPU) ---\n",
        "print(\"--- Dettagli Acceleratore Hardware (GPU/TPU) ---\")\n",
        "try:\n",
        "    tpu_address = os.environ.get('COLAB_TPU_ADDR')\n",
        "    if tpu_address:\n",
        "        resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\n",
        "        tf.config.experimental_connect_to_cluster(resolver)\n",
        "        tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "        print(f\"Tipo Acceleratore: TPU (indirizzo: {tpu_address})\")\n",
        "        print(\"Dispositivi TPU disponibili:\")\n",
        "        for device in tf.config.list_logical_devices('TPU'):\n",
        "            print(f\"  - {device.name}\")\n",
        "    else:\n",
        "        gpus = tf.config.list_physical_devices('GPU')\n",
        "        if gpus:\n",
        "            print(f\"Tipo Acceleratore: GPU\")\n",
        "            for gpu in gpus:\n",
        "                print(f\"  - Dispositivo GPU rilevato: {gpu.name}\")\n",
        "            print(\"\\nDettagli GPU specifici (da `!nvidia-smi`):\")\n",
        "            !nvidia-smi\n",
        "        else:\n",
        "            print(\"Tipo Acceleratore: Nessuna GPU o TPU rilevata (in uso CPU)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Si è verificato un errore durante la rilevazione dell'acceleratore: {e}\")\n",
        "    print(\"Tentativo di rilevare i dispositivi TensorFlow standard:\")\n",
        "    devices = tf.config.list_logical_devices()\n",
        "    if devices:\n",
        "        for device in devices:\n",
        "            print(f\"  - Dispositivo rilevato: {device.name}, Tipo: {device.device_type}\")\n",
        "    else:\n",
        "        print(\"Nessun dispositivo TensorFlow rilevato.\")\n",
        "\n",
        "print(\"\\n--- Analisi Dettagli Hardware Completata ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X46EKvDxpZ-a"
      },
      "source": [
        "# Connect To Gdrive to store the datasets created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7J7tQfWpjXc",
        "outputId": "84a3b285-c219-4946-fb24-c7ca39df4548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGVsmzeNKtlZ"
      },
      "source": [
        "# Define the paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7Qs-TmuKwOY"
      },
      "outputs": [],
      "source": [
        "# Percorsi dataset\n",
        "paths = {\n",
        "    #\"0-20\": {\n",
        "    #    \"train\": \"/content/drive/MyDrive/GitHub/Rayleigh/dataset/UNIFORM_SNR_SAMPLES_training_0-20_SNR_50_BETA.npz\",\n",
        "    #    \"val\": \"/content/drive/MyDrive/GitHub/Rayleigh/dataset/UNIFORM_SNR_SAMPLES_validation_0-20_SNR_50_BETA.npz\",\n",
        "    #},\n",
        "    \"11-15\": {\n",
        "        \"train\": \"/content/drive/MyDrive/GitHub/Rayleigh/dataset/training_11-15_SNR_50_BETA.npz\",\n",
        "        \"val\": \"/content/drive/MyDrive/GitHub/Rayleigh/dataset/validation_11-15_SNR_50_BETA.npz\",\n",
        "    }\n",
        "}\n",
        "\n",
        "# Directory salvataggio modelli\n",
        "save_dir = \"/content/drive/MyDrive/GitHub/AWGN/trained_models/benchmarks\"\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD7ssM5qLY-s"
      },
      "source": [
        "# Load the datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJcjv-xvLcA5"
      },
      "outputs": [],
      "source": [
        "def load_dataset(filepath):\n",
        "    \"\"\"\n",
        "    Carica i dati X e y da un file .npz.\n",
        "    Si aspetta che il file contenga 'X_train' o 'X_val' e 'y_train' o 'y_val'.\n",
        "    \"\"\"\n",
        "    data = np.load(filepath)\n",
        "\n",
        "    # Controlla se le chiavi per il training sono presenti\n",
        "    if 'X_train' in data and 'y_train' in data:\n",
        "        print(f\"  Caricato Training data da: {filepath}\")\n",
        "        return data['X_train'], data['y_train']\n",
        "    # Altrimenti, controlla se le chiavi per la validation sono presenti\n",
        "    elif 'X_val' in data and 'y_val' in data:\n",
        "        print(f\"  Caricato Validation data da: {filepath}\")\n",
        "        return data['X_val'], data['y_val']\n",
        "    else:\n",
        "        # Se nessuna delle combinazioni attese è trovata, solleva un errore\n",
        "        raise ValueError(f\"Il file {filepath} non contiene i dati X e y attesi (né 'X_train'/'y_train' né 'X_val'/'y_val'). \"\n",
        "                         f\"Chiavi trovate: {list(data.keys())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-chXzhHELfQr"
      },
      "source": [
        "# Benchmark models definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UoABDP2KlQI"
      },
      "outputs": [],
      "source": [
        "# Funzioni modello\n",
        "\n",
        "def get_tdnn_model(input_shape, model_name='TDNN OFDM-DCSK'):\n",
        "    # Dal paper: \"Reliable and Secure Deep Learning-Based OFDM-DCSK Transceiver Design Without Delivery of Reference Chaotic Sequences\"\n",
        "    inputs = Input(shape=input_shape)\n",
        "    input_length = input_shape[0]\n",
        "    x = layers.Reshape((input_length, 1), name=\"reshape_for_conv\")(inputs)\n",
        "    x = layers.Conv1D(4, 2, activation='relu', padding='same', name=\"tdnn_conv1\")(x)\n",
        "    x = layers.Conv1D(8, 4, activation='relu', padding='same', name=\"tdnn_conv2\")(x)\n",
        "    x = layers.Conv1D(16, 8, activation='relu', padding='same', name=\"tdnn_conv3\")(x)\n",
        "    x = layers.Bidirectional(layers.LSTM(64, return_sequences=False), name=\"bidirectional_lstm\")(x)\n",
        "    x = layers.Dense(96, name=\"fc1\")(x)\n",
        "    x = layers.BatchNormalization(name=\"batch_norm\")(x)\n",
        "    x = layers.Activation('relu', name=\"relu_fc1\")(x)\n",
        "    outputs = layers.Dense(2, activation='softmax', name=\"output_softmax\")(x)\n",
        "    model = Model(inputs, outputs, name='DNN_Aided_Demodulator')\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def get_mc_dlcs_model(input_shape, model_name='MC-DLCSK'):\n",
        "    # Dal paper: \"A Multi-Carrier Deep Learning CSK Communication System\"\n",
        "    if input_shape[0] % 2 != 0:\n",
        "        raise ValueError(\"input_shape deve essere pari per MC-DLCSK\")\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = layers.Reshape((input_shape[0], 1), name=\"reshape_for_lstm\")(inputs)\n",
        "    x = layers.Bidirectional(layers.LSTM(5, return_sequences=False), name=\"bidirectional_lstm\")(x)\n",
        "    x = layers.Dense(2, activation='relu', name=\"fc1_relu\")(x)\n",
        "    outputs = layers.Dense(2, activation='softmax', name=\"output_softmax\")(x)\n",
        "    model = Model(inputs, outputs, name=model_name)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def get_lstm_dnn_model(input_shape, model_name='LSTM_DNN_OFDM_DCSK'):\n",
        "    # Dal paper: \"Intelligent and Reliable Deep Learning LSTM Neural Networks-Based OFDM-DCSK Demodulation Design\"\n",
        "    inputs = Input(shape=input_shape)\n",
        "    if len(input_shape) == 1:\n",
        "        x = layers.Reshape((1, input_shape[0]))(inputs)\n",
        "    elif len(input_shape) == 2:\n",
        "        x = inputs\n",
        "    else:\n",
        "        raise ValueError(\"input_shape deve essere 1D o 2D\")\n",
        "    # For K=32 (max length in the paper) authors set 77 LSTM units. In Table 1 69 units for the first Dense Layer.\n",
        "    x = layers.LSTM(19)(x)\n",
        "    x = layers.Dense(69, activation='relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    outputs = layers.Dense(2, activation='softmax')(x)\n",
        "    model = Model(inputs, outputs, name=model_name)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def get_two_conv1d_global_avg_pool_attention_model(input_shape, model_name='TwoConv1D_GlobalAvgPool_Attention'):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = layers.Reshape((input_shape[0], 1), name=\"reshape_for_conv\")(inputs)\n",
        "    x = layers.Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', name=\"conv1d_layer_1\")(x)\n",
        "    conv_output_2 = layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', name=\"conv1d_layer_2\")(x)\n",
        "\n",
        "    attention_weights = layers.Conv1D(filters=1, kernel_size=1, activation='sigmoid', name=\"attention_weights\")(conv_output_2)\n",
        "    attended_features = layers.Multiply(name=\"multiply_attention\")([conv_output_2, attention_weights])\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(name=\"global_average_pooling_layer\")(attended_features)\n",
        "    x = layers.Dropout(0.3, name=\"dropout_layer\")(x)\n",
        "    x = layers.Dense(128, activation='relu', name=\"fc1\")(x)\n",
        "    outputs = layers.Dense(2, activation='softmax', name=\"output_softmax\")(x)\n",
        "    model = Model(inputs, outputs, name=model_name)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "models_dict = {\n",
        "    #\"TDNN OFDM-DCSK\": get_tdnn_model,\n",
        "    \"Ultra-CANv3\": get_two_conv1d_global_avg_pool_attention_model,\n",
        "    #\"LSTM_DNN_OFDM_DCSK\": get_lstm_dnn_model\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqhoJHu1Lks5"
      },
      "source": [
        "# Training..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u1TCwRHLmHk",
        "outputId": "ef66852d-7b1f-441c-863c-7a883f206955"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Caricato Training data da: /content/drive/MyDrive/GitHub/Rayleigh/dataset/training_11-15_SNR_50_BETA.npz\n",
            "  Caricato Validation data da: /content/drive/MyDrive/GitHub/Rayleigh/dataset/validation_11-15_SNR_50_BETA.npz\n",
            "\n",
            "Addestramento modello: MC-DLCSK | SNR range: 11-15\n",
            "Epoch 1/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.5881 - loss: 0.6663 - val_accuracy: 0.6194 - val_loss: 0.6233\n",
            "Epoch 2/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - accuracy: 0.5684 - loss: 0.6738 - val_accuracy: 0.6482 - val_loss: 0.6321\n",
            "Epoch 3/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.7126 - loss: 0.5377 - val_accuracy: 0.9758 - val_loss: 0.0734\n",
            "Epoch 4/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9727 - loss: 0.0739 - val_accuracy: 0.9793 - val_loss: 0.0529\n",
            "Epoch 5/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - accuracy: 0.9796 - loss: 0.0527 - val_accuracy: 0.9786 - val_loss: 0.0568\n",
            "Epoch 6/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.9800 - loss: 0.0501 - val_accuracy: 0.9766 - val_loss: 0.0617\n",
            "Epoch 7/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - accuracy: 0.9797 - loss: 0.0484 - val_accuracy: 0.9751 - val_loss: 0.0653\n",
            "Epoch 8/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9792 - loss: 0.0476 - val_accuracy: 0.9798 - val_loss: 0.0491\n",
            "Epoch 9/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.9808 - loss: 0.0446 - val_accuracy: 0.9816 - val_loss: 0.0425\n",
            "Epoch 10/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.9795 - loss: 0.0478 - val_accuracy: 0.9815 - val_loss: 0.0426\n",
            "Epoch 11/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 12ms/step - accuracy: 0.9821 - loss: 0.0436 - val_accuracy: 0.9826 - val_loss: 0.0384\n",
            "Epoch 12/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - accuracy: 0.9821 - loss: 0.0425 - val_accuracy: 0.9826 - val_loss: 0.0386\n",
            "Epoch 13/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.9816 - loss: 0.0439 - val_accuracy: 0.9818 - val_loss: 0.0417\n",
            "Epoch 14/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 12ms/step - accuracy: 0.9826 - loss: 0.0406 - val_accuracy: 0.9828 - val_loss: 0.0385\n",
            "Epoch 15/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9830 - loss: 0.0403 - val_accuracy: 0.9830 - val_loss: 0.0378\n",
            "Epoch 16/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9830 - loss: 0.0396 - val_accuracy: 0.9833 - val_loss: 0.0368\n",
            "Epoch 17/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - accuracy: 0.9838 - loss: 0.0388 - val_accuracy: 0.9777 - val_loss: 0.0544\n",
            "Epoch 18/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9831 - loss: 0.0409 - val_accuracy: 0.9771 - val_loss: 0.0560\n",
            "Epoch 19/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 13ms/step - accuracy: 0.9837 - loss: 0.0387 - val_accuracy: 0.9818 - val_loss: 0.0412\n",
            "Epoch 20/20\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.9844 - loss: 0.0376 - val_accuracy: 0.9839 - val_loss: 0.0370\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training completato.\n",
            "Tempo totale di training: 356.32 secondi.\n",
            "Salvato modello in: /content/drive/MyDrive/GitHub/AWGN/trained_models/benchmarks/MC-DLCSK-ORIGINAL-50-BETA_rayleigh_snr_11-15.h5\n"
          ]
        }
      ],
      "source": [
        "# Addestramento\n",
        "for snr_range, datasets in paths.items():\n",
        "    x_train, y_train = load_dataset(datasets['train'])\n",
        "    x_val, y_val = load_dataset(datasets['val'])\n",
        "\n",
        "    for model_name, builder in models_dict.items():\n",
        "        print(f\"\\nAddestramento modello: {model_name} | SNR range: {snr_range}\")\n",
        "        model = builder(input_shape=x_train.shape[1:])\n",
        "\n",
        "        callback = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "        start_time = time.time() # Registra il tempo di inizio training\n",
        "\n",
        "        # Accordint to the papers...\n",
        "        if model_name==\"MC-DLCSK\":\n",
        "          # As recommended in the original paper.\n",
        "          epochs_nr = 20\n",
        "        else:\n",
        "          epochs_nr = 30\n",
        "\n",
        "        if model_name==\"LSTM_DNN_OFDM_DCSK\":\n",
        "          batch = 20\n",
        "        else:\n",
        "          batch = 50\n",
        "\n",
        "        model.fit(\n",
        "              x_train, y_train,\n",
        "              validation_data=(x_val, y_val),\n",
        "              epochs=epochs_nr,\n",
        "              batch_size=batch,\n",
        "              callbacks=[callback],\n",
        "              verbose=1\n",
        "          )\n",
        "\n",
        "\n",
        "\n",
        "        end_time = time.time() # Registra il tempo di fine training\n",
        "        total_training_time = end_time - start_time\n",
        "\n",
        "        print(f\"Training completato.\")\n",
        "        print(f\"Tempo totale di training: {total_training_time:.2f} secondi.\") # Stampa il tempo totale\n",
        "\n",
        "        save_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}-ORIGINAL-50-BETA_rayleigh_snr_{snr_range}.h5\")\n",
        "        model.save(save_path)\n",
        "        print(f\"Salvato modello in: {save_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr5FHECzXUmH",
        "outputId": "2e20198b-a7a2-4168-cc2a-01982a671345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Caricato Training data da: /content/drive/MyDrive/GitHub/Rayleigh/dataset/training_11-15_SNR_50_BETA.npz\n",
            "  Caricato Validation data da: /content/drive/MyDrive/GitHub/Rayleigh/dataset/validation_11-15_SNR_50_BETA.npz\n",
            "\n",
            "Addestramento modello: Ultra-CANv3 | SNR range: 11-15\n",
            "Epoch 1/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.8345 - loss: 0.3249 - val_accuracy: 0.9766 - val_loss: 0.0565\n",
            "Epoch 2/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9714 - loss: 0.0680 - val_accuracy: 0.9780 - val_loss: 0.0514\n",
            "Epoch 3/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9741 - loss: 0.0615 - val_accuracy: 0.9790 - val_loss: 0.0499\n",
            "Epoch 4/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9747 - loss: 0.0609 - val_accuracy: 0.9787 - val_loss: 0.0474\n",
            "Epoch 5/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9752 - loss: 0.0572 - val_accuracy: 0.9786 - val_loss: 0.0486\n",
            "Epoch 6/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9769 - loss: 0.0560 - val_accuracy: 0.9804 - val_loss: 0.0456\n",
            "Epoch 7/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.9766 - loss: 0.0556 - val_accuracy: 0.9814 - val_loss: 0.0440\n",
            "Epoch 8/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9777 - loss: 0.0531 - val_accuracy: 0.9808 - val_loss: 0.0444\n",
            "Epoch 9/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9780 - loss: 0.0518 - val_accuracy: 0.9755 - val_loss: 0.0531\n",
            "Epoch 10/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9778 - loss: 0.0518 - val_accuracy: 0.9816 - val_loss: 0.0429\n",
            "Epoch 11/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.9781 - loss: 0.0510 - val_accuracy: 0.9811 - val_loss: 0.0427\n",
            "Epoch 12/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9785 - loss: 0.0498 - val_accuracy: 0.9786 - val_loss: 0.0475\n",
            "Epoch 13/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9783 - loss: 0.0493 - val_accuracy: 0.9803 - val_loss: 0.0437\n",
            "Epoch 14/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9784 - loss: 0.0496 - val_accuracy: 0.9805 - val_loss: 0.0435\n",
            "Epoch 15/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9790 - loss: 0.0486 - val_accuracy: 0.9795 - val_loss: 0.0448\n",
            "Epoch 16/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9789 - loss: 0.0484 - val_accuracy: 0.9812 - val_loss: 0.0423\n",
            "Epoch 17/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9794 - loss: 0.0476 - val_accuracy: 0.9823 - val_loss: 0.0414\n",
            "Epoch 18/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9792 - loss: 0.0478 - val_accuracy: 0.9798 - val_loss: 0.0442\n",
            "Epoch 19/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9791 - loss: 0.0486 - val_accuracy: 0.9819 - val_loss: 0.0413\n",
            "Epoch 20/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9798 - loss: 0.0468 - val_accuracy: 0.9822 - val_loss: 0.0407\n",
            "Epoch 21/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.9796 - loss: 0.0466 - val_accuracy: 0.9826 - val_loss: 0.0404\n",
            "Epoch 22/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.9792 - loss: 0.0468 - val_accuracy: 0.9801 - val_loss: 0.0424\n",
            "Epoch 23/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9805 - loss: 0.0459 - val_accuracy: 0.9823 - val_loss: 0.0400\n",
            "Epoch 24/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9798 - loss: 0.0463 - val_accuracy: 0.9798 - val_loss: 0.0429\n",
            "Epoch 25/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9797 - loss: 0.0469 - val_accuracy: 0.9763 - val_loss: 0.0504\n",
            "Epoch 26/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9795 - loss: 0.0481 - val_accuracy: 0.9796 - val_loss: 0.0433\n",
            "Epoch 27/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.9801 - loss: 0.0455 - val_accuracy: 0.9822 - val_loss: 0.0401\n",
            "Epoch 28/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9801 - loss: 0.0458 - val_accuracy: 0.9806 - val_loss: 0.0429\n",
            "Epoch 29/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9798 - loss: 0.0456 - val_accuracy: 0.9816 - val_loss: 0.0408\n",
            "Epoch 30/30\n",
            "\u001b[1m1200/1200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.9789 - loss: 0.0463 - val_accuracy: 0.9816 - val_loss: 0.0403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training completato.\n",
            "Tempo totale di training: 290.59 secondi.\n",
            "Salvato modello in: /content/drive/MyDrive/GitHub/AWGN/trained_models/benchmarks/Ultra-CANv3-ORIGINAL-50-BETA_rayleigh_snr_11-15.h5\n"
          ]
        }
      ],
      "source": [
        "# Addestramento\n",
        "for snr_range, datasets in paths.items():\n",
        "    x_train, y_train = load_dataset(datasets['train'])\n",
        "    x_val, y_val = load_dataset(datasets['val'])\n",
        "\n",
        "    for model_name, builder in models_dict.items():\n",
        "        print(f\"\\nAddestramento modello: {model_name} | SNR range: {snr_range}\")\n",
        "        model = builder(input_shape=x_train.shape[1:])\n",
        "\n",
        "        callback = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
        "\n",
        "        start_time = time.time() # Registra il tempo di inizio training\n",
        "\n",
        "        # Accordint to the papers...\n",
        "        if model_name==\"MC-DLCSK\":\n",
        "          # As recommended in the original paper.\n",
        "          epochs_nr = 20\n",
        "        else:\n",
        "          epochs_nr = 30\n",
        "\n",
        "        if model_name==\"LSTM_DNN_OFDM_DCSK\":\n",
        "          batch = 20\n",
        "        else:\n",
        "          batch = 50\n",
        "\n",
        "        model.fit(\n",
        "              x_train, y_train,\n",
        "              validation_data=(x_val, y_val),\n",
        "              epochs=epochs_nr,\n",
        "              batch_size=batch,\n",
        "              callbacks=[callback],\n",
        "              verbose=1\n",
        "          )\n",
        "\n",
        "\n",
        "\n",
        "        end_time = time.time() # Registra il tempo di fine training\n",
        "        total_training_time = end_time - start_time\n",
        "\n",
        "        print(f\"Training completato.\")\n",
        "        print(f\"Tempo totale di training: {total_training_time:.2f} secondi.\") # Stampa il tempo totale\n",
        "\n",
        "        save_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}-ORIGINAL-50-BETA_rayleigh_snr_{snr_range}.h5\")\n",
        "        model.save(save_path)\n",
        "        print(f\"Salvato modello in: {save_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "OBZ65HW9CLdc",
        "gD7ssM5qLY-s"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}