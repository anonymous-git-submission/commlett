{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "OEAfQA05D6ua",
        "AujxZNQWMBuP",
        "OBZ65HW9CLdc",
        "YGVsmzeNKtlZ",
        "gD7ssM5qLY-s",
        "NXQc617k2ef5",
        "_uDMOm207dmY",
        "HqhoJHu1Lks5",
        "1e-tqOmfH2_W"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the libraries"
      ],
      "metadata": {
        "id": "OEAfQA05D6ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import platform\n",
        "from tensorflow.keras import layers, optimizers, losses, models, Input, Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import time # Per misurare il tempo di training\n",
        "from tensorflow.keras.callbacks import EarlyStopping # Per l'early stopping\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm # Per mostrare una barra di progresso"
      ],
      "metadata": {
        "id": "cAkyZrEzu97V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set seeds for random operations."
      ],
      "metadata": {
        "id": "AujxZNQWMBuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M=4\n",
        "BETA = 50\n",
        "\n",
        "# --- 1. Impostazione del Seed Globale all'inizio del tuo script ---\n",
        "# Questo è il punto chiave per la riproducibilità di TUTTO ciò che segue.\n",
        "MASTER_RANDOM_SEED = 42\n",
        "np.random.seed(MASTER_RANDOM_SEED)\n",
        "random.seed(MASTER_RANDOM_SEED) # Imposta anche il seed per la libreria 'random' di Python se la usi\n",
        "tf.random.set_seed(MASTER_RANDOM_SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(MASTER_RANDOM_SEED) # Per operazioni basate su hash (es. ordine dei dizionari)\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1' # Forza operazioni deterministiche in TensorFlow 2.x"
      ],
      "metadata": {
        "id": "uXGzTxrOME1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Print the HW Specs."
      ],
      "metadata": {
        "id": "OBZ65HW9CLdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Dettagli dell'Architettura Hardware della Sessione Colab ---\\n\")\n",
        "\n",
        "# --- 1. Dettagli CPU ---\n",
        "print(\"--- Dettagli CPU ---\")\n",
        "!lscpu\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 2. Dettagli RAM (Memoria) ---\n",
        "print(\"--- Dettagli RAM (Memoria) ---\")\n",
        "!cat /proc/meminfo | grep MemTotal\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 3. Dettagli Spazio su Disco ---\n",
        "print(\"--- Dettagli Spazio su Disco ---\")\n",
        "!df -h /\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- 4. Dettagli Acceleratore Hardware (GPU/TPU) ---\n",
        "print(\"--- Dettagli Acceleratore Hardware (GPU/TPU) ---\")\n",
        "try:\n",
        "    tpu_address = os.environ.get('COLAB_TPU_ADDR')\n",
        "    if tpu_address:\n",
        "        resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\n",
        "        tf.config.experimental_connect_to_cluster(resolver)\n",
        "        tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "        print(f\"Tipo Acceleratore: TPU (indirizzo: {tpu_address})\")\n",
        "        print(\"Dispositivi TPU disponibili:\")\n",
        "        for device in tf.config.list_logical_devices('TPU'):\n",
        "            print(f\"  - {device.name}\")\n",
        "    else:\n",
        "        gpus = tf.config.list_physical_devices('GPU')\n",
        "        if gpus:\n",
        "            print(f\"Tipo Acceleratore: GPU\")\n",
        "            for gpu in gpus:\n",
        "                print(f\"  - Dispositivo GPU rilevato: {gpu.name}\")\n",
        "            print(\"\\nDettagli GPU specifici (da `!nvidia-smi`):\")\n",
        "            !nvidia-smi\n",
        "        else:\n",
        "            print(\"Tipo Acceleratore: Nessuna GPU o TPU rilevata (in uso CPU)\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Si è verificato un errore durante la rilevazione dell'acceleratore: {e}\")\n",
        "    print(\"Tentativo di rilevare i dispositivi TensorFlow standard:\")\n",
        "    devices = tf.config.list_logical_devices()\n",
        "    if devices:\n",
        "        for device in devices:\n",
        "            print(f\"  - Dispositivo rilevato: {device.name}, Tipo: {device.device_type}\")\n",
        "    else:\n",
        "        print(\"Nessun dispositivo TensorFlow rilevato.\")\n",
        "\n",
        "print(\"\\n--- Analisi Dettagli Hardware Completata ---\")"
      ],
      "metadata": {
        "id": "BBhq145cCO9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ed9b24-013b-405c-c2cf-61f1f4620a03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Dettagli dell'Architettura Hardware della Sessione Colab ---\n",
            "\n",
            "--- Dettagli CPU ---\n",
            "Architecture:             x86_64\n",
            "  CPU op-mode(s):         32-bit, 64-bit\n",
            "  Address sizes:          46 bits physical, 48 bits virtual\n",
            "  Byte Order:             Little Endian\n",
            "CPU(s):                   2\n",
            "  On-line CPU(s) list:    0,1\n",
            "Vendor ID:                GenuineIntel\n",
            "  Model name:             Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "    CPU family:           6\n",
            "    Model:                85\n",
            "    Thread(s) per core:   2\n",
            "    Core(s) per socket:   1\n",
            "    Socket(s):            1\n",
            "    Stepping:             3\n",
            "    BogoMIPS:             4000.38\n",
            "    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge m\n",
            "                          ca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht sysc\n",
            "                          all nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xt\n",
            "                          opology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq\n",
            "                           ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt\n",
            "                           aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dno\n",
            "                          wprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase\n",
            "                           tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm m\n",
            "                          px avx512f avx512dq rdseed adx smap clflushopt clwb av\n",
            "                          x512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsave\n",
            "                          s arat md_clear arch_capabilities\n",
            "Virtualization features:  \n",
            "  Hypervisor vendor:      KVM\n",
            "  Virtualization type:    full\n",
            "Caches (sum of all):      \n",
            "  L1d:                    32 KiB (1 instance)\n",
            "  L1i:                    32 KiB (1 instance)\n",
            "  L2:                     1 MiB (1 instance)\n",
            "  L3:                     38.5 MiB (1 instance)\n",
            "NUMA:                     \n",
            "  NUMA node(s):           1\n",
            "  NUMA node0 CPU(s):      0,1\n",
            "Vulnerabilities:          \n",
            "  Gather data sampling:   Not affected\n",
            "  Itlb multihit:          Not affected\n",
            "  L1tf:                   Mitigation; PTE Inversion\n",
            "  Mds:                    Vulnerable; SMT Host state unknown\n",
            "  Meltdown:               Vulnerable\n",
            "  Mmio stale data:        Vulnerable\n",
            "  Reg file data sampling: Not affected\n",
            "  Retbleed:               Vulnerable\n",
            "  Spec rstack overflow:   Not affected\n",
            "  Spec store bypass:      Vulnerable\n",
            "  Spectre v1:             Vulnerable: __user pointer sanitization and usercopy b\n",
            "                          arriers only; no swapgs barriers\n",
            "  Spectre v2:             Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-eIB\n",
            "                          RS: Not affected; BHI: Vulnerable\n",
            "  Srbds:                  Not affected\n",
            "  Tsx async abort:        Vulnerable\n",
            "\n",
            "\n",
            "--- Dettagli RAM (Memoria) ---\n",
            "MemTotal:       13289424 kB\n",
            "\n",
            "\n",
            "--- Dettagli Spazio su Disco ---\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         113G   39G   75G  34% /\n",
            "\n",
            "\n",
            "--- Dettagli Acceleratore Hardware (GPU/TPU) ---\n",
            "Tipo Acceleratore: GPU\n",
            "  - Dispositivo GPU rilevato: /physical_device:GPU:0\n",
            "\n",
            "Dettagli GPU specifici (da `!nvidia-smi`):\n",
            "Thu Jul 24 09:52:04 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8              8W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "\n",
            "--- Analisi Dettagli Hardware Completata ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect To Gdrive to store the datasets created."
      ],
      "metadata": {
        "id": "X46EKvDxpZ-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7J7tQfWpjXc",
        "outputId": "2f5e2a44-9d61-4a19-f66d-5e34902ac8d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the paths"
      ],
      "metadata": {
        "id": "YGVsmzeNKtlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Percorsi dataset\n",
        "paths = {\n",
        "\n",
        "    #\"0-20\": {\n",
        "    #    \"train\": \"/content/drive/MyDrive/GitHub/Rayleigh/dataset/UNIFORM_SNR_SAMPLES_training_0-20_SNR_50_BETA.npz\",\n",
        "    #    \"val\": \"/content/drive/MyDrive/GitHub/Rayleigh/dataset/UNIFORM_SNR_SAMPLES_validation_0-20_SNR_50_BETA.npz\",\n",
        "    #},\n",
        "    \"11-15\": {\n",
        "         \"train\": \"/content/drive/MyDrive/GitHub/Rayleigh/dataset/training_11-15_SNR_50_BETA.npz\",\n",
        "         \"val\": \"/content/drive/MyDrive/GitHub/Rayleigh/dataset/validation_11-15_SNR_50_BETA.npz\",\n",
        "    }\n",
        "}\n",
        "\n",
        "# Directory salvataggio modelli\n",
        "save_dir = \"/content/drive/MyDrive/GitHub/Rayleigh/trained_models/benchmarks\"\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "G7Qs-TmuKwOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the datasets."
      ],
      "metadata": {
        "id": "gD7ssM5qLY-s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(filepath):\n",
        "    \"\"\"\n",
        "    Carica i dati X e y da un file .npz.\n",
        "    Si aspetta che il file contenga 'X_train' o 'X_val' e 'y_train' o 'y_val'.\n",
        "    \"\"\"\n",
        "    data = np.load(filepath)\n",
        "\n",
        "    # Controlla se le chiavi per il training sono presenti\n",
        "    if 'X_train' in data and 'y_train' in data:\n",
        "        print(f\"  Caricato Training data da: {filepath}\")\n",
        "        return data['X_train'], data['y_train']\n",
        "    # Altrimenti, controlla se le chiavi per la validation sono presenti\n",
        "    elif 'X_val' in data and 'y_val' in data:\n",
        "        print(f\"  Caricato Validation data da: {filepath}\")\n",
        "        return data['X_val'], data['y_val']\n",
        "    else:\n",
        "        # Se nessuna delle combinazioni attese è trovata, solleva un errore\n",
        "        raise ValueError(f\"Il file {filepath} non contiene i dati X e y attesi (né 'X_train'/'y_train' né 'X_val'/'y_val'). \"\n",
        "                         f\"Chiavi trovate: {list(data.keys())}\")"
      ],
      "metadata": {
        "id": "VJcjv-xvLcA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model version definitions."
      ],
      "metadata": {
        "id": "NXQc617k2ef5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Funzioni per definire i modelli ---\n",
        "\n",
        "def get_two_conv1d_global_avg_pool_attention_model(input_shape, model_name='TwoConv1D_GlobalAvgPool_Attention'):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = layers.Reshape((input_shape[0], 1), name=\"reshape_for_conv\")(inputs)\n",
        "    x = layers.Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', name=\"conv1d_layer_1\")(x)\n",
        "    conv_output_2 = layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', name=\"conv1d_layer_2\")(x)\n",
        "\n",
        "    attention_weights = layers.Conv1D(filters=1, kernel_size=1, activation='sigmoid', name=\"attention_weights\")(conv_output_2)\n",
        "    attended_features = layers.Multiply(name=\"multiply_attention\")([conv_output_2, attention_weights])\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(name=\"global_average_pooling_layer\")(attended_features)\n",
        "    x = layers.Dropout(0.3, name=\"dropout_layer\")(x)\n",
        "    x = layers.Dense(128, activation='relu', name=\"fc1\")(x)\n",
        "    outputs = layers.Dense(2, activation='softmax', name=\"output_softmax\")(x)\n",
        "    model = Model(inputs, outputs, name=model_name)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def get_two_conv1d_global_avg_pool_attention_light_model(input_shape, model_name='TwoConv1D_GlobalAvgPool_Attention_Light'):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = layers.Reshape((input_shape[0], 1), name=\"reshape_for_conv\")(inputs)\n",
        "    x = layers.Conv1D(filters=24, kernel_size=3, activation='relu', padding='same', name=\"conv1d_layer_1\")(x)\n",
        "    conv_output_2 = layers.Conv1D(filters=32, kernel_size=3, activation='relu', padding='same', name=\"conv1d_layer_2\")(x)\n",
        "\n",
        "    attention_weights = layers.Conv1D(filters=1, kernel_size=1, activation='sigmoid', name=\"attention_weights\")(conv_output_2)\n",
        "    attended_features = layers.Multiply(name=\"multiply_attention\")([conv_output_2, attention_weights])\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(name=\"global_average_pooling_layer\")(attended_features)\n",
        "    x = layers.Dropout(0.3, name=\"dropout_layer\")(x)\n",
        "    x = layers.Dense(64, activation='relu', name=\"fc1\")(x)\n",
        "    outputs = layers.Dense(2, activation='softmax', name=\"output_softmax\")(x)\n",
        "    model = Model(inputs, outputs, name=model_name)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def get_two_conv1d_global_avg_pool_attention_heavy_model(input_shape, model_name='TwoConv1D_GlobalAvgPool_Attention_Heavy'):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = layers.Reshape((input_shape[0], 1), name=\"reshape_for_conv\")(inputs)\n",
        "    x = layers.Conv1D(filters=48, kernel_size=3, activation='relu', padding='same', name=\"conv1d_layer_1\")(x)\n",
        "    conv_output_2 = layers.Conv1D(filters=96, kernel_size=3, activation='relu', padding='same', name=\"conv1d_layer_2\")(x)\n",
        "\n",
        "    attention_weights = layers.Conv1D(filters=96, kernel_size=1, activation='sigmoid', name=\"attention_weights\")(conv_output_2)\n",
        "    attended_features = layers.Multiply(name=\"multiply_attention\")([conv_output_2, attention_weights])\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(name=\"global_average_pooling_layer\")(attended_features)\n",
        "    x = layers.Dropout(0.3, name=\"dropout_layer\")(x)\n",
        "    x = layers.Dense(128, activation='relu', name=\"fc1\")(x)\n",
        "    outputs = layers.Dense(2, activation='softmax', name=\"output_softmax\")(x)\n",
        "    model = Model(inputs, outputs, name=model_name)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def get_two_conv1d_global_avg_pool_attention_TD_model(input_shape, model_name='TwoConv1D_GlobalAvgPool_Attention_TD'):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Reshape input to (timesteps, 1) if it's 1D\n",
        "    x = layers.Reshape((input_shape[0], 1), name=\"reshape_for_conv\")(inputs)  # (batch, time_steps, 1)\n",
        "\n",
        "    # Conv layers\n",
        "    x = layers.Conv1D(filters=48, kernel_size=3, activation='relu', padding='same', name=\"conv1d_layer_1\")(x)\n",
        "    conv_output_2 = layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='same', name=\"conv1d_layer_2\")(x)\n",
        "\n",
        "    # Attention\n",
        "    attention_weights = layers.Conv1D(filters=64, kernel_size=1, activation='sigmoid', name=\"attention_weights\")(conv_output_2)\n",
        "    attended_features = layers.Multiply(name=\"multiply_attention\")([conv_output_2, attention_weights])  # shape: (batch, time_steps, 64)\n",
        "\n",
        "    # TimeDistributed Dense\n",
        "    x = layers.TimeDistributed(layers.Dense(32, activation='relu'), name=\"td_dense_1\")(attended_features)  # still (batch, time_steps, 32)\n",
        "\n",
        "    # GlobalAveragePooling1D to collapse time dimension\n",
        "    x = layers.GlobalAveragePooling1D(name=\"global_average_pooling_layer\")(x)  # (batch, 32)\n",
        "\n",
        "    # FC layers\n",
        "    x = layers.Dropout(0.3, name=\"dropout_layer\")(x)\n",
        "    x = layers.Dense(12, activation='relu', name=\"fc1\")(x)\n",
        "    outputs = layers.Dense(2, activation='softmax', name=\"output_softmax\")(x)\n",
        "\n",
        "    model = Model(inputs, outputs, name=model_name)\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# --- Dizionario dei modelli ---\n",
        "\n",
        "models_dict = {\n",
        "    \"TwoConv1D_GlobalAvgPool_Attention\": get_two_conv1d_global_avg_pool_attention_model,\n",
        "    \"TwoConv1D_GlobalAvgPool_Attention_Light\": get_two_conv1d_global_avg_pool_attention_light_model,\n",
        "    #\"TwoConv1D_GlobalAvgPool_Attention_Heavy\": get_two_conv1d_global_avg_pool_attention_heavy_model,\n",
        "    \"TwoConv1D_GlobalAvgPool_Attention_TD\": get_two_conv1d_global_avg_pool_attention_TD_model,\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "u60o3FJU2jBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training per 30 Epoche."
      ],
      "metadata": {
        "id": "ZM-sSMIXa_G5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Addestramento\n",
        "for snr_range, datasets in paths.items():\n",
        "    x_train, y_train = load_dataset(datasets['train'])\n",
        "    x_val, y_val = load_dataset(datasets['val'])\n",
        "\n",
        "    for model_name, builder in models_dict.items():\n",
        "        print(f\"\\nAddestramento modello: {model_name} | SNR range: {snr_range}\")\n",
        "        model = builder(input_shape=x_train.shape[1:])\n",
        "\n",
        "        callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "        start_time = time.time() # Registra il tempo di inizio training\n",
        "\n",
        "        model.fit(\n",
        "             x_train, y_train,\n",
        "             validation_data=(x_val, y_val),\n",
        "             epochs=30,\n",
        "             batch_size=25,\n",
        "             callbacks=[callback],\n",
        "             verbose=1\n",
        "        )\n",
        "\n",
        "        end_time = time.time() # Registra il tempo di fine training\n",
        "        total_training_time = end_time - start_time\n",
        "\n",
        "        print(f\"Training completato.\")\n",
        "        print(f\"Tempo totale di training: {total_training_time:.2f} secondi.\") # Stampa il tempo totale\n",
        "\n",
        "        save_path = os.path.join(save_dir, f\"{model_name.replace(' ', '_')}-ORIGINALv2-50-BETA_rayleigh_RANDOM_snr_{snr_range}.h5\")\n",
        "        model.save(save_path)\n",
        "        #ber_values, snr_points = calculate_ber(model, beta=BETA, m =M)\n",
        "\n",
        "        print(f\"Salvato modello in: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SulihoNJbBJN",
        "outputId": "375c95f1-bfa6-4776-af1f-394587e6d07d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Caricato Training data da: /content/drive/MyDrive/GitHub/Rayleigh/dataset/training_11-15_SNR_50_BETA.npz\n",
            "  Caricato Validation data da: /content/drive/MyDrive/GitHub/Rayleigh/dataset/validation_11-15_SNR_50_BETA.npz\n",
            "\n",
            "Addestramento modello: TwoConv1D_GlobalAvgPool_Attention | SNR range: 11-15\n",
            "Epoch 1/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.8629 - loss: 0.2635 - val_accuracy: 0.9714 - val_loss: 0.0647\n",
            "Epoch 2/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 7ms/step - accuracy: 0.9715 - loss: 0.0693 - val_accuracy: 0.9786 - val_loss: 0.0504\n",
            "Epoch 3/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.9739 - loss: 0.0630 - val_accuracy: 0.9747 - val_loss: 0.0618\n",
            "Epoch 4/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9755 - loss: 0.0589 - val_accuracy: 0.9769 - val_loss: 0.0526\n",
            "Epoch 5/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.9749 - loss: 0.0583 - val_accuracy: 0.9765 - val_loss: 0.0521\n",
            "Epoch 6/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9761 - loss: 0.0569 - val_accuracy: 0.9801 - val_loss: 0.0452\n",
            "Epoch 7/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 7ms/step - accuracy: 0.9776 - loss: 0.0528 - val_accuracy: 0.9789 - val_loss: 0.0461\n",
            "Epoch 8/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.9775 - loss: 0.0530 - val_accuracy: 0.9793 - val_loss: 0.0453\n",
            "Epoch 9/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9779 - loss: 0.0519 - val_accuracy: 0.9818 - val_loss: 0.0447\n",
            "Epoch 10/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9777 - loss: 0.0511 - val_accuracy: 0.9795 - val_loss: 0.0462\n",
            "Epoch 11/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0507 - val_accuracy: 0.9792 - val_loss: 0.0466\n",
            "Epoch 12/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 6ms/step - accuracy: 0.9785 - loss: 0.0502 - val_accuracy: 0.9808 - val_loss: 0.0440\n",
            "Epoch 13/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9783 - loss: 0.0504 - val_accuracy: 0.9809 - val_loss: 0.0430\n",
            "Epoch 14/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9789 - loss: 0.0486 - val_accuracy: 0.9815 - val_loss: 0.0417\n",
            "Epoch 15/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9788 - loss: 0.0488 - val_accuracy: 0.9815 - val_loss: 0.0422\n",
            "Epoch 16/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.9788 - loss: 0.0496 - val_accuracy: 0.9811 - val_loss: 0.0424\n",
            "Epoch 17/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9790 - loss: 0.0484 - val_accuracy: 0.9821 - val_loss: 0.0417\n",
            "Epoch 18/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9799 - loss: 0.0454 - val_accuracy: 0.9800 - val_loss: 0.0447\n",
            "Epoch 19/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9782 - loss: 0.0477 - val_accuracy: 0.9820 - val_loss: 0.0410\n",
            "Epoch 20/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9794 - loss: 0.0480 - val_accuracy: 0.9818 - val_loss: 0.0408\n",
            "Epoch 21/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9791 - loss: 0.0475 - val_accuracy: 0.9809 - val_loss: 0.0420\n",
            "Epoch 22/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.9796 - loss: 0.0458 - val_accuracy: 0.9800 - val_loss: 0.0439\n",
            "Epoch 23/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9802 - loss: 0.0453 - val_accuracy: 0.9794 - val_loss: 0.0441\n",
            "Epoch 24/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9801 - loss: 0.0456 - val_accuracy: 0.9805 - val_loss: 0.0425\n",
            "Epoch 25/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9806 - loss: 0.0453 - val_accuracy: 0.9822 - val_loss: 0.0405\n",
            "Epoch 26/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 7ms/step - accuracy: 0.9793 - loss: 0.0466 - val_accuracy: 0.9820 - val_loss: 0.0404\n",
            "Epoch 27/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 6ms/step - accuracy: 0.9807 - loss: 0.0450 - val_accuracy: 0.9816 - val_loss: 0.0406\n",
            "Epoch 28/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9798 - loss: 0.0452 - val_accuracy: 0.9815 - val_loss: 0.0410\n",
            "Epoch 29/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.9803 - loss: 0.0449 - val_accuracy: 0.9816 - val_loss: 0.0408\n",
            "Epoch 30/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9799 - loss: 0.0452 - val_accuracy: 0.9804 - val_loss: 0.0423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completato.\n",
            "Tempo totale di training: 573.78 secondi.\n",
            "Salvato modello in: /content/drive/MyDrive/GitHub/Rayleigh/trained_models/benchmarks/TwoConv1D_GlobalAvgPool_Attention-ORIGINALv2-50-BETA_rayleigh_RANDOM_snr_11-15.h5\n",
            "\n",
            "Addestramento modello: TwoConv1D_GlobalAvgPool_Attention_Light | SNR range: 11-15\n",
            "Epoch 1/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.8519 - loss: 0.3003 - val_accuracy: 0.9728 - val_loss: 0.0659\n",
            "Epoch 2/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9685 - loss: 0.0743 - val_accuracy: 0.9749 - val_loss: 0.0590\n",
            "Epoch 3/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9704 - loss: 0.0708 - val_accuracy: 0.9764 - val_loss: 0.0543\n",
            "Epoch 4/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9710 - loss: 0.0684 - val_accuracy: 0.9764 - val_loss: 0.0558\n",
            "Epoch 5/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9732 - loss: 0.0637 - val_accuracy: 0.9765 - val_loss: 0.0541\n",
            "Epoch 6/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9733 - loss: 0.0636 - val_accuracy: 0.9789 - val_loss: 0.0486\n",
            "Epoch 7/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9734 - loss: 0.0617 - val_accuracy: 0.9804 - val_loss: 0.0469\n",
            "Epoch 8/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9749 - loss: 0.0586 - val_accuracy: 0.9782 - val_loss: 0.0522\n",
            "Epoch 9/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.9762 - loss: 0.0567 - val_accuracy: 0.9808 - val_loss: 0.0463\n",
            "Epoch 10/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9755 - loss: 0.0571 - val_accuracy: 0.9800 - val_loss: 0.0459\n",
            "Epoch 11/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9761 - loss: 0.0561 - val_accuracy: 0.9794 - val_loss: 0.0458\n",
            "Epoch 12/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9767 - loss: 0.0546 - val_accuracy: 0.9793 - val_loss: 0.0458\n",
            "Epoch 13/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9758 - loss: 0.0544 - val_accuracy: 0.9801 - val_loss: 0.0443\n",
            "Epoch 14/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9758 - loss: 0.0551 - val_accuracy: 0.9798 - val_loss: 0.0442\n",
            "Epoch 15/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9768 - loss: 0.0539 - val_accuracy: 0.9793 - val_loss: 0.0461\n",
            "Epoch 16/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9769 - loss: 0.0538 - val_accuracy: 0.9800 - val_loss: 0.0452\n",
            "Epoch 17/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0528 - val_accuracy: 0.9810 - val_loss: 0.0427\n",
            "Epoch 18/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9778 - loss: 0.0511 - val_accuracy: 0.9813 - val_loss: 0.0422\n",
            "Epoch 19/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9775 - loss: 0.0516 - val_accuracy: 0.9797 - val_loss: 0.0447\n",
            "Epoch 20/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0507 - val_accuracy: 0.9815 - val_loss: 0.0425\n",
            "Epoch 21/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9778 - loss: 0.0508 - val_accuracy: 0.9805 - val_loss: 0.0431\n",
            "Epoch 22/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9785 - loss: 0.0499 - val_accuracy: 0.9811 - val_loss: 0.0418\n",
            "Epoch 23/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9781 - loss: 0.0495 - val_accuracy: 0.9808 - val_loss: 0.0422\n",
            "Epoch 24/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9787 - loss: 0.0503 - val_accuracy: 0.9785 - val_loss: 0.0473\n",
            "Epoch 25/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9785 - loss: 0.0498 - val_accuracy: 0.9797 - val_loss: 0.0433\n",
            "Epoch 26/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9784 - loss: 0.0494 - val_accuracy: 0.9799 - val_loss: 0.0435\n",
            "Epoch 27/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0509 - val_accuracy: 0.9813 - val_loss: 0.0421\n",
            "Epoch 28/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9793 - loss: 0.0494 - val_accuracy: 0.9794 - val_loss: 0.0440\n",
            "Epoch 29/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 6ms/step - accuracy: 0.9788 - loss: 0.0488 - val_accuracy: 0.9803 - val_loss: 0.0432\n",
            "Epoch 30/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 6ms/step - accuracy: 0.9780 - loss: 0.0494 - val_accuracy: 0.9791 - val_loss: 0.0448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completato.\n",
            "Tempo totale di training: 598.19 secondi.\n",
            "Salvato modello in: /content/drive/MyDrive/GitHub/Rayleigh/trained_models/benchmarks/TwoConv1D_GlobalAvgPool_Attention_Light-ORIGINALv2-50-BETA_rayleigh_RANDOM_snr_11-15.h5\n",
            "\n",
            "Addestramento modello: TwoConv1D_GlobalAvgPool_Attention_TD | SNR range: 11-15\n",
            "Epoch 1/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.8844 - loss: 0.2415 - val_accuracy: 0.9780 - val_loss: 0.0530\n",
            "Epoch 2/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.9718 - loss: 0.0659 - val_accuracy: 0.9783 - val_loss: 0.0497\n",
            "Epoch 3/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.9744 - loss: 0.0599 - val_accuracy: 0.9783 - val_loss: 0.0503\n",
            "Epoch 4/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 16ms/step - accuracy: 0.9754 - loss: 0.0576 - val_accuracy: 0.9805 - val_loss: 0.0449\n",
            "Epoch 5/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.9769 - loss: 0.0543 - val_accuracy: 0.9802 - val_loss: 0.0444\n",
            "Epoch 6/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.9778 - loss: 0.0517 - val_accuracy: 0.9805 - val_loss: 0.0433\n",
            "Epoch 7/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.9771 - loss: 0.0525 - val_accuracy: 0.9804 - val_loss: 0.0445\n",
            "Epoch 8/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 15ms/step - accuracy: 0.9782 - loss: 0.0509 - val_accuracy: 0.9815 - val_loss: 0.0414\n",
            "Epoch 9/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.9782 - loss: 0.0497 - val_accuracy: 0.9817 - val_loss: 0.0413\n",
            "Epoch 10/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.9786 - loss: 0.0489 - val_accuracy: 0.9804 - val_loss: 0.0433\n",
            "Epoch 11/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.9783 - loss: 0.0498 - val_accuracy: 0.9818 - val_loss: 0.0414\n",
            "Epoch 12/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.9797 - loss: 0.0477 - val_accuracy: 0.9805 - val_loss: 0.0433\n",
            "Epoch 13/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.9799 - loss: 0.0472 - val_accuracy: 0.9806 - val_loss: 0.0425\n",
            "Epoch 14/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 15ms/step - accuracy: 0.9797 - loss: 0.0460 - val_accuracy: 0.9782 - val_loss: 0.0468\n",
            "Epoch 15/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 15ms/step - accuracy: 0.9809 - loss: 0.0453 - val_accuracy: 0.9809 - val_loss: 0.0419\n",
            "Epoch 16/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.9811 - loss: 0.0465 - val_accuracy: 0.9786 - val_loss: 0.0449\n",
            "Epoch 17/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.9809 - loss: 0.0449 - val_accuracy: 0.9780 - val_loss: 0.0460\n",
            "Epoch 18/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 15ms/step - accuracy: 0.9809 - loss: 0.0447 - val_accuracy: 0.9761 - val_loss: 0.0511\n",
            "Epoch 19/30\n",
            "\u001b[1m2400/2400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 15ms/step - accuracy: 0.9813 - loss: 0.0439 - val_accuracy: 0.9747 - val_loss: 0.0539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completato.\n",
            "Tempo totale di training: 770.32 secondi.\n",
            "Salvato modello in: /content/drive/MyDrive/GitHub/Rayleigh/trained_models/benchmarks/TwoConv1D_GlobalAvgPool_Attention_TD-ORIGINALv2-50-BETA_rayleigh_RANDOM_snr_11-15.h5\n"
          ]
        }
      ]
    }
  ]
}